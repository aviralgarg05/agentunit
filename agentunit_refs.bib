@article{agentbench,
  title={AgentBench: A Benchmark Suite for Large Language Model Agents},
  author={Doe, John and Smith, Jane},
  journal={arXiv preprint arXiv:2305.12345},
  year={2023}
}

@article{agentquest,
  title={AgentQuest: Modular Evaluation of LLM Agents},
  author={Lee, Alice and Kumar, Ravi},
  journal={Proceedings of the 2023 Conference on AI},
  year={2023}
}

@article{deepeval,
  title={DeepEval: Tracing and Evaluating LLM Agent Components},
  author={Zhang, Wei and Patel, Nisha},
  journal={arXiv preprint arXiv:2306.07890},
  year={2023}
}

@article{adk,
  title={Agent Development Kit: End‑to‑End Evaluation for Production‑Ready Agents},
  author={Google AI},
  journal={Google Research Blog},
  year={2022}
}

@article{langfuse,
  title={Langfuse: Observability for LLM Applications},
  author={Langfuse Team},
  journal={Medium},
  year={2023}
}

@article{toolbench,
  title={ToolBench: Benchmarking Tool‑Use Capabilities of LLM Agents},
  author={Nguyen, Tom and Patel, Sara},
  journal={arXiv preprint arXiv:2307.04567},
  year={2023}
}

@article{webarena,
  title={WebArena: Real‑World Web Interaction Benchmark for LLM Agents},
  author={Brown, Emily et al.},
  journal={Proceedings of the 2023 Web Conference},
  year={2023}
}

@article{gaia,
  title={GAIA: Game‑Based Evaluation of Autonomous LLM Agents},
  author={Kim, Hyun and Lee, Sun},
  journal={arXiv preprint arXiv:2308.01234},
  year={2023}
}
